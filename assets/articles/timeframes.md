### Is Superintelligence Coming?

notes:
Disclaimer: my opinions are based on relatively modest research as I’m pretty early in the journey. I invite any corrections to anything I’ve written that is wrong.

The current hype cycle presents our incremental improvements and applications of modern machine learning techniques as rapid steps towards a fuzzy and general “AI” concept. There are some cool sounding achievements being announced almost weekly, but they’re all still within extremely narrow specifications. 

Stepping back a bit, in my opinion most of modern machine learning techniques (an example chosen because they’re popular in the media at the moment) are more about smart programmers applying clever statistical techniques than scientists creating a process that might actually result (by itself, or individually significantly contribute to) in emergent consciousness or a generalised intelligence.

As an example, deep neural networks are:
- not very deep. A depth of 30 nodes (a settable hyperparameter chosen by the person creating the network, realistically limited by hardware) is impressively deep (http://thenewstack.io/deep-learning-neural-networks-google-deep-dream/) whereas real neurons equivalent “depth” is between 2 and 10,000-100,000 (https://www.reddit.com/r/MachineLearning/comments/432hht/depth_of_the_human_neural_network/czfbj4n/).
- not really neural. Apart from being loosely inspired by neurons, a node in a neural network is a simple number/transformation compared with the deeply complex neurons (of which there are many different types) in our brains.
- barely networked - the number of local connections each neuron has in something like a convolutional neural network is also a hyperparameter but essentially always minuscule by comparison to their real squishy counterparts (http://www.human-memory.net/brain_neurons.html).

Fundamentally, deep neural nets don’t really model the brain and aren’t really particularly related to concepts of general intelligence (in my opinion) in the same way the brain might be (http://www.turingfinance.com/misconceptions-about-neural-networks/).

My point is that the hype that creates a sense of nearness does not match up with reality. AI research has progressed, like many fields, at a fairly steady pace since it’s inception.

Research is a slow process and we are so incredibly far from understanding the basis of intelligence itself, I think it is hopelessly optimistic to suggest we are anywhere near creating (and controlling) it artificially. (A cool read on that https://www.engadget.com/2016/08/15/technological-singularity-problems-brain-mind/). Ask a room full of neuroscientists and neurologists how intelligence works and you’ll get a bunch of laughter.

This is getting a tad long for a Facebook comment and the arguments are not properly sourced so I’ll write up a proper blog post at some point as this is an interesting topic. I’ll share it here when I get around to it!

Finally, just to be clear, I still think that the possibility of creating general artificial intelligence in 100 years is a terrifying concept and we’re being typically shortsighted as a species and not dealing with it properly at all. Hence my membership of this group and enjoyment of your podcasts!
